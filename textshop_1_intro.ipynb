{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to textshop\n",
    "\n",
    "What we are going to do today:\n",
    "\n",
    "1. Learn more about why we are all here in this room.\n",
    "2. Enjoy the fact that we're getting swag: 32GB flash drives loaded with software, documents, and data. (Okay, we're going to need to deal with text as *data*.)\n",
    "3. If we have internet and a projector, then we're going to play with Google ngrams, Google web analytics, things like that (maybe a live Twitter visualization).\n",
    "4. We need to talk about assembling datasets: troubles with access and quality as well as cleaning data. \n",
    "5. And then we're going to run some text mining tools, principally Voyant, locally and explore possible next steps in term's of user's interests. \n",
    "\n",
    "**Useful**:\n",
    "* Previous workshops on text mining, aka *text analytics*, have used [Voyant Tools][] and [Python][].\n",
    "\n",
    "[Voyant Tools]: http://github.com/cpence/text-mining-workshop\n",
    "[Python]: http://github.com/johnlaudun/pyta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Today\n",
    "\n",
    "John Laudun  \n",
    "Department of English  \n",
    "University of Louisiana at Lafayette  \n",
    "laudun@louisiana.edu\n",
    "http://johnlaudun.org/  \n",
    "@johnlaudun  \n",
    "\n",
    "All of today's notebooks, along with the data, will be available at: http://github.com/johnlaudun/workshop\n",
    "\n",
    "The software and documents have their own websites and are already available separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "**Ex. 1.** Demonstrable proof that Austen is better at writing dialogue than Stoker: treat each speaker as an author and then do stylometric analysis of them: table of function words used by speakers reveals which words each speaker \"prefers.\" Chunking of Stoker's speakers.\n",
    "\n",
    "**Ex. 2.** Sentiment analysis of social media feeds.\n",
    "\n",
    "**Ex. 3.** Networking science articles by genes mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Tools\n",
    "\n",
    "**Tool 1.** Google Books Ngram Viewer now has PoS tagging, e.g., `tackling_noun, tackling_verb` and mathematical operators, e.g., `apple sauce/(apple sauce + applesauce)`. (Datasets are now downloadable, but they are quite large.)\n",
    "\n",
    "**Tool 2.** HathiTrust Bookworm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling Your Own Datasets\n",
    "\n",
    "Places to get stuff:\n",
    "\n",
    "* Project Gutenberg: (http://gutenberg.org/)\n",
    "* Google Books (http://books.google.com)\n",
    "* EEBO (http://quod.lib.umich.edu/e/eebogroup/)\n",
    "* ECCO (http://quod.lib.umich.edu/e/ecco/)\n",
    "* Evans (http://quod.lib.umich.edu/e/evans/)\n",
    "\n",
    "* JSTOR DFR (http://dfr.jstor.org/)\n",
    "* Open Access: \n",
    "    * PMC Open Access Set\n",
    "    * PLoS\n",
    "    * BioMed Central\n",
    "\n",
    "* _Mining the Social Web_ (O'Reilly)\n",
    "* Twitter APIs (http://dev.twitter.com)\n",
    "* Facebook APIs (http://developers/facebook.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubles with Access and Quality\n",
    "\n",
    "The elephant in the room is copyright. For-profit journals: Elsevier has a text-mining API; otherwise negotiation contracts. The same holds true for contemporary books: getting access can be difficult, even with HathiTrust.\n",
    "\n",
    "Google Ngram brings up other issues: the digitization of available materials is not complete, which suggests that the statistical significance is limited, even in contemporary English. Worries about breadth of corpus, especially in early works. Libraries scan the books they have, and libraries tend to have (still) medical and scientific volumes. E.g., any signal you get could be weak or just plain wrong. OCR noise can run wildly high.\n",
    "\n",
    "re: Social media, see: Boyd and Crawford 2011 (SSRN: 1926431).\n",
    "\n",
    "Not only is OCR problematic, but automated tasks, like named entity extraction, are also questionable. (Pence prefers ABBYY Fine Reader over Acrobat Pro.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Tools: Voyant\n",
    "\n",
    "Append `/tool/Bubblelines` to the URL and it will give you some interesting results.\n",
    "\n",
    "Also: \n",
    "\n",
    "    /tool/DocumentTypeCollocateFrequenciesGrid\n",
    "    /tool/Links\n",
    "    /tool/RezoViz\n",
    "\n",
    "David Hu at NYU has some Excel spreadsheets that analyze by zeta algorithms. (\"I'm not sure how the Craig zeta algorithm works, but it gives great results.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
